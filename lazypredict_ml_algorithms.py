# -*- coding: utf-8 -*-
"""Lazypredict_ML_Algorithms.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/197XFOhshD-4XSJDVCE45cchaPf4k1eJn
"""

pip install lazypredict

"""**Implementation of Lazypredict :**

1.   classification
2.   Regression

**Classification**

**Note** : use  [Google colab](https://colab.research.google.com/)
"""

# importing LazyClassifier for classification problem
# importing LazyClassifier for classification problem because here we are solving Classification use case.
## importing breast Cancer Dataset from sklearn
# spliting dataset into training and testing part
from lazypredict.Supervised import LazyClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# The data set 
data= load_breast_cancer()

"""--> separating dataset into dependent and independent features"""

x=data.data

y=data.target

### splitting dataset into training and testing part(20% training and 80% testing)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2,random_state=123)
clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)

models,predictions=clf.fit(x_train,x_test,y_train,y_test)

print(models)

"""**Regression**"""

from lazypredict.Supervised import LazyRegressor
from sklearn import datasets
from sklearn.utils import shuffle
import numpy as np

#The dataset 
boston = datasets.load_boston()
# loading and shuffling the dataset
X, y = shuffle(boston.data, boston.target, random_state=13)
X = X.astype(np.float32)
offset = int(X.shape[0] * 0.9)

# splitting dataset into training and testing part.
X_train, y_train = X[:offset], y[:offset]
X_test, y_test = X[offset:], y[offset:]
# fitting data in LazyRegressor because here we are solving Regression use case.
reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )
models,predictions = reg.fit(X_train, X_test, y_train, y_test)

print(models)

"""**NOTE**

During a machine learing project , we often look to get the best possible  results by trying  the multiple algorithms .
This is extremly time consuming . 
Indeed , for each algorithm , we may have to load  new d libraries , declare a new object, re-train the model and store the results .
The python library called **Lazypredict**  allows us to test a set of the most used algorithms in data science in one go !!!!

It is really  useful , especially to have a first overview  and to know  which machine learning  solution to turn to for Further analysis .


--- source: [lazypredict](https://lazypredict.readthedocs.io/en/latest/)

Krishna Dev Adhikari Danuwar \
Khwopa Engineering College \
Bhaktapur , Nepal\
gmail:[74Krishnadev@gmail.com]\
LinkedIn:[Krishna Dev Adhikari Danuwar](https://www.linkedin.com/in/krishnadev-adhikari-danuwar/)
"""

